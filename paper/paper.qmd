---
title: "Forecasting the 2024 US Presidential Election"
subtitle: "A Poll-of-Polls Approach Using Bayesian Modeling"
author: 
  - Xinqi Yue
  - Yawen Tan
  - Duanyi Su
thanks: "Code and data are available at: [https://github.com/xinqiyue/2024_US_Election_Prediction](https://github.com/xinqiyue/2024_US_Election_Prediction)."
date: today
date-format: long
abstract: "This paper builds a predictive Bayesian model to forecast the 2024 US presidential election using a “poll-of-polls” approach, analyzing high-quality polls for Kamala Harris and Donald Trump. The model incorporates data on polling methodology, state trends, and candidate support. Our findings indicate that xxxxxxxx. This study contributes to a deeper understanding of electoral forecasting, helping us interpret aggregated polling data to anticipate election results accurately."
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(arrow)
```

```{r}
#| include: false
#| warning: false
#| message: false
# load data
president_polls_cleaned_data <- read_parquet('../data/02-analysis_data/president_polls_cleaned_data.parquet')
# transfer date to standard form
president_polls_cleaned_data$end_date <- ymd(president_polls_cleaned_data$end_date)
```




```{r}
#| echo: false
#| warning: false
#| message: false
# plot graph of pct of two candidates in each state against time
ggplot(president_polls_cleaned_data, aes(x = end_date, y = pct
                                         #, color = state
                                         )
       ) +
  geom_point() +
  facet_wrap(~ candidate_name, scales = "free_y") +
  theme_minimal() +
  #theme(legend.position = "bottom") +
  labs(
    y = "pct",
    x = "end date",
    color = "state",
    title = "pct of Donald Trump and Kamala Harris in each states",
  )
```

# Introduction
The 2024 U.S. presidential election is generating significant public interest, with recent polling reflecting shifts in candidate support across various demographic and regional groups. Polling data, while insightful, presents challenges due to inherent biases, variability in polling methodology, and regional influences on voter behavior. This study aims to address these challenges using a "poll-of-polls" approach, aggregating high-quality national and state polls to forecast voter support for Kamala Harris and Donald Trump. By applying Bayesian modeling, this analysis incorporates both the temporal dynamics of candidate support and state-specific trends.

In this paper, we explore the following questions: How is support for each candidate likely to evolve as the election approaches? How do regional differences influence overall voter sentiment? This paper contributes to electoral forecasting literature by synthesizing aggregated polling data to provide a nuanced view of candidate support trends.

## Estimand

Our primary estimand is the percentage of voter support for Donald Trump and Kamala Harris on election day. We estimate this support percentage both at the national level and by state, incorporating time and state-specific effects.

Results paragraph

Why it matters paragraph

Telegraphing paragraph: The remainder of this paper is structured as follows. @sec-data....



# Data {#sec-data}

## Data Overview {#sec-data-overview}
The dataset encompasses polling data focused on two candidates, Donald Trump and Kamala Harris. Data has been filtered to include only results from pollsters with a numeric grade above 2.5 to maintain quality and consistency. This selection allows us to focus on higher-rated sources, which may enhance the reliability of predictions. Each record includes information on the pollster, their grading, polling methodology, transparency score, and specific polling results for each candidate.

The analysis utilizes FiveThirtyEight's dataset of national presidential general election polls [@fivethirtyeight]. Following the approach outlined in [@tellingstories], we aim to predict the election outcome based on this polling data. The analyses were conducted in R @citeR, with support from several packages. The `tidyverse` packages [@citetidyverse] were used in the process of data simulation, testing beforehand. After the original raw data was downloaded by using `tidyverse` package [@citetidyverse], data cleaning process was done by using `tidyverse` package [@citetidyverse], `lubridate` package [@citelubridate], and `arrow` package [@citearrow]. Then, models were constructed using `tidyverse` package [@citetidyverse], `lubridate` package [@citelubridate], `rstanarm` [@citerstanarm] package, and `splines` package [@citesplines]. The model results are then presented by `modelsummary` [@citemodelsummary] package, and graphs were made with `ggplot2` package [@citeggplot].

## Data Clean
We clean the raw data to produce the analysis dataset using the tools listed in the @sec-data-overview, providing high-quality data for subsequent election analysis. Firstly, we standardize column names to lowercase and remove special characters. Then, we retain only the fields relevant to the election analysis, such as `state`, `end_date`, `sample_size`, `candidate_name`, and `pct` (percentage support), simplifying the data structure by removing unnecessary columns. Next, we remove rows with missing values and replace empty values in the `state` column with "National," indicating these records pertain to nationwide polls. Additionally, we convert the `end_date` column to date format, ensuring accuracy in date-based filtering. Then, we filter the data to retain only records that meet specific criteria: a `numeric_grade` of 2.5 or higher, a `candidate_name` of either "Kamala Harris" or "Donald Trump" (focusing on these two candidates' support levels), an `end_date` on or after July 21, 2024 (focusing on recent polling when Biden withdrawal from the election), and a non-empty `end_date` (filtering out records with missing dates).

The cleaned data is displayed in @tbl-analysis-data-1, which contains a total of 5 variables:
```{r}
#| label: tbl-analysis-data-1
#| tbl-cap: First 6 entries of Analysis Dataset
#| echo: false
#| warning: false
#| message: false

#Graph
head_analysis_data <- head(president_polls_cleaned_data,6)
# Note there is a type in Description within the original data set itself
knitr::kable(head_analysis_data[, 1:5], format = "simple", col.names = c('State','End date','Sample Size', 'Canadidate Name','PCT'))

```

## Predictors Explanation
- **state**: The U.S. state where the poll was conducted, which allows for state-by-state analysis and comparison of support levels.

- **end date**: The date the poll concluded, marking the end of data collection for that specific poll.

- **sample size**: The number of respondents in the poll, indicating the scope and potential statistical reliability of the results.

- **candidate_name**: The name of the candidate being polled, which in this data set focuses on Donald Trump and Kamala Harris.

## Outcome Exaplanation

- **pct**: The support percentage each candidate received in the poll, which serves as the outcome variable for analysis.

## Explanation of Other Variables Used
- **pollster**: The organization that conducted the poll, providing information on who gathered the data.
  
- **numeric grade**: A quality score assigned to the pollster, with higher values indicating greater reliability. Only pollsters with a score above 2.5 are included to enhance accuracy.

- **pollscore**: A specific rating of the individual poll, reflecting additional factors that impact the poll's quality and reliability.

- **methodology**: The method used by the pollster to conduct the poll, which may affect the reliability and interpretation of the results.

- **transparency score**: A measure of how openly the pollster reports their methodology and results. Higher scores suggest greater transparency and reliability.

## Measurement
The goal of this measurement is to turn individual voter opinions into a reliable estimate of electoral college outcomes by analyzing polling data. This data, sourced from @fivethirtyeight—a trusted platform known for high standards—includes only polls that meet rigorous quality criteria, ensuring broad representation of likely U.S. voters. Polls provide essential details, such as the pollster’s identity, survey dates, sample size, and methodology, covering data collection mode, demographic weighting, and adjustments to create a representative sample. These quality standards, while robust, are based on historical practices, which may overlook recent methodological shifts or emerging biases.

## Limitation
Polling has inherent limitations. It provides snapshots of voter sentiment at specific times rather than ongoing updates, potentially missing rapid shifts in public opinion, especially near Election Day. Adjustments are made for recency, but participation and response biases—like self-selection and social desirability bias—can still impact accuracy by creating gaps between expressed opinions and actual voting behavior. Additionally, regional polling disparities, with battleground states polled more frequently than “safe” states, can lead to imbalances in representation, highlighting the challenge of achieving uniformly accurate forecasts across the nation.

## Data visualization
### Exploring the Relationship Between State and PCT

```{r}
#| label: fig-pct-state
#| fig-cap: Support for Candidates by State
#| echo: false
#| warning: false
#| message: false

# Load ggplot2
library(ggplot2)

ggplot(data = president_polls_cleaned_data, aes(x = state, y = pct, fill = candidate_name)) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_manual(values = c("Donald Trump" = "pink", "Kamala Harris" = "lightblue")) + 
  labs(x = "State",
       y = "Support Percentage (%)") + # Add X-axis and Y-axis
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
```

### Exploring the Relationship Between End Date and PCT

```{r}
#| label: fig-pct-time
#| fig-cap: Trends in Candidate Support Over Time
#| echo: false
#| warning: false
#| message: false

# Load ggplot2
library(ggplot2)

ggplot(data = president_polls_cleaned_data, aes(x = end_date, y = pct, color = candidate_name, group = candidate_name)) +
  #geom_line(size = 1,alpha = 0.5) + 
  geom_point(size = 1) + # Add data point
  geom_smooth(se = FALSE) + 
  scale_color_manual(values = c("Donald Trump" = "pink", "Kamala Harris" = "lightblue")) + 
  labs(x = "State",
       y = "Support Percentage (%)") + # Add X-axis and Y-axis
  theme_minimal() + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(legend.position = "bottom")
```


# Model
In this analysis, we use a Bayesian linear regression model to estimate the percentage of support (`pct`) for each candidate in the upcoming US presidential election. The model includes key predictors such as polling end date (`end_date`), candidate (`candidate_name`), sample size (`sample_size`), and state (`state`). Each predictor is selected based on its relevance to the variation in candidate support, as discussed in the data section.

## Model set-up

In this Bayesian framework, support level are modeled as normally distributed and influenced by several predictors: end date, candidate name, sample size, and state. The variable $y_i$ denotes the percentage of votes for a candidate in a specific poll, with $\beta_i$ representing the candidate effect, $\gamma_i$ reflecting the influence of sample size, and $\delta_i$ corresponding to the state effect. The intercept $\alpha$ indicates the baseline poll result, while each $\beta_i$ coefficient quantifies the influence of its associated predictor on the vote percentage. Additionally, the variable $\text{state}_j$ captures the effects attributed to different states, and $\text{end\_date}_{i}$ models temporal trends.

The model can be mathematically expressed as follows:

\begin{align}
y_i | \mu_i, \sigma &\sim \text{Normal}(\mu_i, \sigma) \\ 
\mu_i &= \alpha + \beta_1 \cdot \text{end\_date}_i + \beta_2 \cdot \text{candidate\_name}_i + \beta_3 \cdot \text{sample\_size}_i + \sum_{j=1}^{M} \gamma_j \cdot \text{state}_j \\ 
\alpha &\sim \text{Normal}(50, 10) \\ 
\beta_1, \beta_2, \beta_3 &\sim \text{Normal}(0, 2.5) \\ 
\gamma_j &\sim \text{Normal}(0, 2.5) \\ 
\sigma &\sim \text{Exponential}(1)
\end{align}

Priors are defined as follows. For the intercept, a `Normal(50, 10)` distribution is utilized, reflecting a belief that the baseline support percentage is centered around 50% with moderate variability. This choice indicates a moderately informative prior that captures plausible ranges for the intercept. Each regression coefficient is assigned a `Normal(0, 2.5)` prior, which is weakly informative, allowing flexibility in parameter estimation while minimizing bias. These priors are selected to strike a balance between allowing the data to inform estimates and providing regularization to prevent extreme values and overfitting. The chosen priors are grounded in reasonable expectations regarding support ranges, aiming to enhance the robustness of the model.

Then, the complete model, summarizing the components, can be expressed as:

$$y_i \sim \text{Normal}\left(\alpha + \beta_1 \cdot \text{end\_date}_i + \beta_2 \cdot \text{candidate\_name}_i + \beta_3 \cdot \text{sample\_size}_i + \sum_{j=1}^{M} \gamma_j \cdot \text{state}_j, \sigma^2\right)$$

To further clarify the model:

- **Formula (1)** shows that the response variable $y_i$ is normally distributed, with $\mu_i$ as the expected value and $\sigma$ representing standard deviation.
- **Formula (2)** illustrates that $\mu_i$ is derived from the intercept $\alpha$ and the predictors.
- **Formula (3)** details the basis functions applied to the state variable, allowing for a nuanced relationship between states and vote percentages.
The prior distributions are:
- **Formula (4)** specifies that $\alpha$ has a normal distribution with mean 50 and variance $10^2$, indicating our expectation of average vote percentage.
- **Formula (5)** outlines the priors for $\gamma_k$, which are normal distributions centered at 0 with variance $2.5^2$, reflecting the belief in potentially small effects from state variables.
- **Formula (6)** assigns an exponential distribution to the standard deviation $\sigma$, suggesting that smaller variance is more likely while allowing for broader variations.

## Assumptions of the Bayesian Models

1. **Linearity**: The model assumes a linear relationship between independent variables (predictors) and the dependent variable (outcome, `pct`). The expected outcome is represented as a linear combination of the predictors. Nonlinear effects, if present, may not be fully captured, potentially affecting the model's fit.

2. **Normality of Errors**: It is assumed that the residuals (the differences between observed and predicted values) follow a normal distribution. This assumption is crucial for making valid inferences; violations can lead to incorrect conclusions and unreliable credible intervals. Diagnostic checks and posterior predictive checks are used to assess model fit and adherence to assumptions.

3. **Homoscedasticity**: The variance of the residuals is expected to be constant across all combinations of the predictors. If residuals display heteroscedasticity (non-constant variance), it can result in inefficient estimates and biased interpretations of the modeled relationships.

4. **Independence of Errors**: The model assumes that errors are independent of one another, meaning the error term for any single observation does not affect the error term for another observation. However, polling data often includes repeated measures from the same pollster, which may introduce dependence among observations.

5. **Additivity**: Predictors are assumed to additively influence `pct`, meaning interactions or non-additive effects are not considered. Future versions of the model might benefit from testing interactions, such as between state and candidate.

6. **Prior Distributions**: Bayesian regression requires the specification of prior distributions for the model parameters (coefficients). The selection of these priors is significant, as they can impact the resulting posterior distributions, particularly when data is limited.

7. **Parameter Estimation**: In Bayesian linear regression, parameters are estimated using a posterior distribution derived from both the likelihood of the observed data and the prior distributions. This framework allows for uncertainty quantification and more flexible inference.

## Software and Validation

The model is implemented using the `rstanarm` package in R, which allows for efficient Bayesian inference with automatic convergence diagnostics. Model fit and convergence were monitored through trace plots and effective sample sizes. To further ensure robustness, we performed posterior predictive checks using `pp_check(model_bayes)` to evaluate model fit and identify any systematic deviations.

Overall, this Bayesian model provides a balanced approach, capturing key effects while maintaining interpretability and flexibility, making it suitable for predicting candidate support percentages in the election context.


### Model justification

We expect a positive relationship between the size of the wings and time spent aloft. In particular...

We can use maths by including latex between dollar signs, for instance $\theta$.


# Results

Our results are summarized in @tbl-modelresults.

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

library(rstanarm)

first_model <-
  readRDS(file = here::here("models/first_model.rds"))
```

```{r}
#| echo: false
#| eval: true
#| label: tbl-modelresults
#| tbl-cap: "Explanatory models of flight time based on wing width and wing length"
#| warning: false

modelsummary::modelsummary(
  list(
    "First model" = first_model
  ),
  statistic = "mad",
  fmt = 2
)
```




# Discussion

## Overview of the Paper
This paper presents a comprehensive analysis of polling data to forecast support for candidates Kamala Harris and Donald Trump in the upcoming U.S. presidential election. By employing a Bayesian linear regression model, the study investigates how various factors such as polling date, candidate identity, sample size, and geographic location influence voter support. The findings contribute to understanding the dynamics of electoral support and the effectiveness of polling methodologies in predicting election outcomes.

## Insights About the World
One significant insight derived from this analysis is the importance of temporal dynamics in voter support. The model highlights that the timing of polling can substantially impact the reported support for candidates. This finding suggests that voters’ preferences are not static; rather, they fluctuate based on current events, campaign strategies, and media coverage. Such insights underscore the need for political strategists and candidates to consider timing when conducting polls and planning campaign efforts.

Another critical takeaway is the varying levels of support for candidates across different states. The analysis reveals regional disparities in voter sentiment, indicating that geographic factors significantly influence political preferences. This highlights the importance of localized campaign strategies and targeted outreach, as what resonates in one state may not hold true in another. Understanding these regional differences can enhance candidates' ability to connect with voters and tailor their messaging effectively.

## Limitations of the Study
Despite its contributions, the study is not without weaknesses. One notable limitation is the reliance on existing polling data, which may introduce biases if the data collection methods are not standardized across pollsters. Variations in methodology, sample demographics, and question phrasing can lead to discrepancies in reported support levels. Additionally, the model assumes a linear relationship between predictors and outcomes, which may oversimplify the complexities of voter behavior. A more nuanced approach that incorporates non-linear effects or interactions between variables could provide deeper insights into voter dynamics.

## Future Directions
Looking ahead, several avenues for further research emerge from this study. First, it would be valuable to explore the impact of specific events, such as debates or major news stories, on voter sentiment. Incorporating real-time data and sentiment analysis from social media could enrich the understanding of how public opinion shifts in response to external influences. Furthermore, expanding the model to include demographic factors—such as age, income, and education—could yield a more comprehensive picture of voter support and the diverse motivations behind electoral choices.

In conclusion, while this paper offers valuable insights into electoral dynamics, it also highlights the complexities of voter behavior and the need for continued exploration in this field. Future research should strive to incorporate a broader range of variables and methodologies to enhance the predictive accuracy of electoral forecasts and better inform political strategy.

\newpage

\appendix

# Appendix {-}

# Methodology Analysis of Texas Politics Project Poll{#sec-Appendix1}

## Introduction
This section provides a examination of the methodology utilized by YouGov for the October 2024 Texas Statewide Survey (@blank2024), stating the reliability of the organization and its methods, along with an analysis of the survey's strengths, weaknesses, and potential improvements.

## Population, Frame, and Sample
- **Population**: The survey aimed to represent Texas registered voters, defined as individuals who meet the eligibility requirements to vote in Texas, including age, residency, and registration status. This demographic is critical given the state’s political landscape and upcoming elections.
  
- **Frame**: The sampling frame is the specific population from which a sample is drawn, constructed from diverse data sources to ensure validity. Key components included:
  - **American Community Survey (ACS)**: This provides demographic information that reflects the socio-economic characteristics of Texas residents, essential for establishing a representative sampling frame.
  - **Public voter registration records**: These ensure that the survey captures a valid sample of registered voters, allowing for accurate political representation.
  - **2020 Current Population Survey (CPS)** and **National Election Pool (NEP) exit polls**: These sources offer insights into voting behaviors and preferences, enriching the sampling frame with relevant context and historical data.

- **Sample Size**: The initial sample comprised 1,338 respondents, which was refined to 1,200 for the final dataset through a process known as matching. This process enhances the demographic representativeness of the sample across key characteristics such as gender, age, race, and education.

## Sample Recruitment

- **Recruitment Methods**: YouGov employs a proprietary opt-in survey panel that includes approximately 1.5 million U.S. residents. Key recruitment methods include:
  - **Web Advertising Campaigns**: Targeted ads based on keyword searches increase the likelihood of engaging relevant respondents, leveraging digital platforms for broad reach.
  - **Permission-Based Email Campaigns**: This method allows for direct outreach to potential participants who have expressed interest in surveys, ensuring a more willing and engaged respondent pool.
  - **Telephone-to-Web and Mail-to-Web Recruitment**: These methods broaden the outreach, ensuring access to respondents who may not engage online, thus increasing the overall sample diversity.

- **Diversity and Representation**: The multifaceted recruitment strategy is designed to mitigate biases and enhance the demographic diversity of the panel. This is essential for capturing a representative sample in a politically diverse state like Texas.

## Sampling Approach and Trade-offs

- **Two-Stage Sampling Approach**: 
  1. **Target Sample Selection**: A probability sample is drawn from the defined target population, ensuring it accurately reflects the demographic composition of Texas. Probability sampling means that each individual in the population has a known, non-zero chance of being selected.
  2. **Matched Sample Selection**: Each target sample member is matched to one or more respondents from the YouGov panel, utilizing a set of variables available in consumer and voter databases. Matching involves finding respondents in the panel who share key demographic and behavioral traits with the target sample.

- **Strengths**: This methodology allows for the creation of a sample that closely mirrors the target population’s characteristics, theoretically increasing the external validity of the survey results—external validity refers to the extent to which findings can be generalized to a broader context beyond the study sample.

- **Weaknesses**:
  - **Non-Random Selection**: The reliance on an opt-in panel introduces potential biases associated with self-selection. Respondents who choose to participate may differ significantly from those who do not, potentially affecting the survey's internal validity (the degree to which the survey accurately measures what it intends to measure).
  - **Matching Limitations**: While proximity matching aims to find the closest respondents, it may not account for all variables that could influence responses, leading to unobserved biases. Unobserved biases occur when factors influencing survey responses are not measured or controlled for in the analysis.

## Handling Non-Response

- **Weighting Strategy**: To address non-response bias, YouGov implemented a robust weighting methodology:
  - **Propensity Score Adjustment**: This involves estimating the likelihood of response based on demographic characteristics, which are then used to weight the matched cases back to the target population. Propensity score weighting is a statistical technique that adjusts for differences in observed characteristics between respondents and non-respondents.

- **Challenges**: The success of this strategy hinges on accurate assumptions regarding non-response characteristics, which can be difficult to ascertain. If the reasons for non-response are systematically related to the survey topics or demographics, this could undermine the validity of the results, highlighting the importance of addressing potential non-response bias.

## Questionnaire Evaluation

- **Question Design**: The YouGov questionnaire included a series of structured questions aimed at eliciting clear responses regarding voter preferences and opinions on key issues. Structured questions are those that offer fixed response options, facilitating easier analysis.

- **Pros**:
  - **Clarity and Relevance**: Questions were designed to be straightforward, addressing current political concerns likely to engage respondents effectively.
  - **Comprehensive Coverage**: The questionnaire covered a wide array of topics pertinent to the election, providing rich data for analysis and ensuring relevant insights into voter sentiment.

- **Cons**:
  - **Length and Complexity**: The extensive nature of the questionnaire could lead to respondent fatigue, increasing the likelihood of incomplete or rushed responses, which may affect data quality. Respondent fatigue occurs when participants become tired or disengaged from a survey, leading to lower-quality data.
  - **Framing and Bias**: The manner in which questions are framed can introduce bias. Questions that lack neutral wording may lead to skewed responses based on how they are interpreted by participants, potentially distorting the data collected.

## Recommendations for Improvement

1. **Enhanced Recruitment Strategies**: Consider integrating more diverse recruitment channels, such as partnerships with community organizations, to reach underrepresented groups who may not be captured through standard methods.

2. **Improved Matching Techniques**: Exploring advanced statistical techniques or machine learning approaches for matching respondents could enhance the accuracy of the matched sample.

3. **Shortening the Questionnaire**: Streamlining the questionnaire to focus on the most critical issues could reduce respondent fatigue and improve engagement, ensuring higher quality data collection.

4. **Pilot Testing**: Implementing pilot surveys to test question clarity and structure could help identify potential biases or misunderstandings before full deployment, ensuring that the questions effectively capture the desired information.

5. **Transparency in Weighting Methods**: Clearly communicating the assumptions and methods used in weighting would enhance transparency and allow for a more critical evaluation of the findings, fostering trust in the results.

## Conclusion

In summary, YouGov’s methodology for the October 2024 Texas Statewide Survey demonstrates several strengths, particularly in its diverse recruitment strategies and thorough weighting processes. However, inherent challenges associated with opt-in panels, matching techniques, and questionnaire design warrant careful consideration. By addressing these weaknesses and implementing the suggested improvements, the reliability and validity of future surveys can be enhanced, ultimately providing richer insights into voter behavior and preferences.

# Appendix: Idealized Methodology and Survey {#sec-Appendix2}

## Objective and Overview
This survey methodology aims to forecast the U.S. presidential election outcome by gathering representative data from a diverse cross-section of American voters. The target population includes all eligible U.S. voters, spanning a wide array of demographic backgrounds. With a budget of $100,000, this methodology employs probability sampling techniques, effective recruitment, and thorough data validation protocols to ensure data accuracy and minimize bias. By applying probability sampling, each individual has a known chance of selection, allowing the results to be statistically valid and generalizable. This design accounts for demographic, geographic, and political influences, enhancing prediction reliability [@fivethirty; @pewresearch].

### Core Objectives
- **Representative Sampling**: Achieve a sample reflecting U.S. voting demographics, ensuring insights are applicable to the entire electorate.
- **Data Quality**: Implement validation processes, including cross-verification, to ensure accuracy.
- **Statistical Modeling and Aggregation**: Apply statistical models and aggregate polling data to enhance forecast accuracy, as demonstrated in prior election studies.

## Sampling Strategy
The sampling strategy combines **stratified random sampling** and **quota sampling** for comprehensive representation across key demographics. Stratified random sampling ensures each subgroup within the population is represented by dividing the population into strata (e.g., age, gender, race) and sampling randomly within each stratum. Quota sampling supplements this by guaranteeing minimum representation across essential demographics.

### Stratification Variables
- **Age Groups**: 18-29, 30-44, 45-64, 65+
  - **Gender**: Male, Female, Non-binary/Other
- **Race/Ethnicity**: White, Black, Hispanic/Latino, Asian, Indigenous, Other
- **Education Level**: No high school, High school graduate, College graduate, Post-graduate
- **Income Bracket**: <$30,000, $30,000-$60,000, $60,000-$100,000, >$100,000
- **Geographic Region**: Northeast, Midwest, South, West

This structure aligns with survey sampling best practices, improving accuracy by ensuring proportional representation [@taherdoost2016sampling; @pewresearch]. However, balancing stratification variables with cost considerations remains a challenge, as over-stratification can be cost-inefficient.

### Sample Size
To achieve high accuracy, we will survey **10,000 respondents**, which provides a ±1% margin of error at a 95% confidence level. This sample size enables detailed subgroup analyses, such as state or demographic-specific trends, increasing the forecast’s reliability.

### Weighting
Post-stratification weighting will adjust for any underrepresented or oversampled demographic groups, ensuring the final sample accurately mirrors the voting population [@kalton2003weighting]. For example, younger voters or minorities will be weighted according to their population proportions.

## Recruitment Strategy
**Multi-channel outreach** (digital ads, email, and civic organization partnerships) will mitigate non-response bias by ensuring diverse respondent participation. This strategy helps correct response imbalances that could distort survey accuracy [@dillman2014internet].

- **Digital Advertisements**: Targeted ads on platforms like Facebook and Instagram to attract diverse demographic groups.
- **Email Outreach**: Invitations to registered voters via available databases.
- **Civic Partnerships**: Collaborations with non-profits to enhance diversity and reduce non-response bias.
- **Incentives**: Participants can enter a lottery for a $100 gift card as motivation.

## Data Validation and Quality Assurance
Ensuring data integrity is essential for an accurate election forecast. Validation protocols will include:
  
  - **Captcha Verification**: To prevent bot entries.
- **Contact Verification**: Confirm email or phone authenticity.
- **Response Time Monitoring**: Flag unusually quick completions for review.
- **Voter Registration Check**: If feasible, confirm registration to verify eligibility.
- **Audits**: Random follow-ups to verify responses.

These measures align with data integrity standards in electoral polling [@pew_survey_methodology].

## Poll Aggregation and Data Analysis
### Poll Aggregation
Using a poll-of-polls approach, this survey’s data will combine with data from reputable polling firms (e.g., YouGov, Ipsos), creating a balanced forecast.

- **Weighting by Methodology and Recency**: Polls are weighted based on methodological rigor and recency, favoring recent data.
- **Bias and Variability Adjustments**: Aggregated data will adjust for any bias among individual polls.

### Modeling Approach
**Bayesian hierarchical models** will address variability across states, demographics, and regions, enabling both popular vote and Electoral College predictions.

## Budget Allocation
- **Recruitment and Outreach**: $70,000
- **Incentives**: $10,000
- **Survey Platform and Administration**: $5,000
- **Validation Tools**: $5,000
- **Analysis Software**: $10,000

## Survey Implementation
The survey will be conducted through **Google Forms**, providing an accessible, cost-effective platform. Access the survey here: [Google Form Survey](https://forms.gle/sAxVuk3n9gV8e2odA).

### Survey Structure

\begingroup
\small

**Introduction**: Thank you for participating in our survey to forecast the 2024 U.S. Presidential election outcome. Your responses will remain confidential, and participation is voluntary.

**Section 1: Eligibility Screening**:
  - U.S. citizenship and voter eligibility questions.

**Section 2: Demographics**:
  - Questions on age, gender, race, education, income, and region.

**Section 3: Political Views and Voting Intentions**:
  - Likelihood of voting, party affiliation, candidate choice, and issue importance.

**Section 4: Engagement and Information Sources**:
  - Questions about primary news sources and engagement with election coverage.

**End Message**: Thank you for your time. For survey inquiries, please contact [duanyi.su@mail.utoronto.ca](mailto:duanyi.su@mail.utoronto.ca).

\endgroup

---
  
### Design Considerations
- **Question Wording**: Structured to be clear, neutral, and direct.
- **Pilot Testing**: A pre-deployment pilot will refine the question flow, ensuring clarity and ease for respondents.

\newpage
# Additional data details

# Model details {#sec-model-details}

## Posterior predictive check

In @fig-ppcheckandposteriorvsprior-1 we implement a posterior predictive check. This shows...

In @fig-ppcheckandposteriorvsprior-2 we compare the posterior with the prior. This shows... 


## Diagnostics

@fig-stanareyouokay-1 is a trace plot. It shows... This suggests...

@fig-stanareyouokay-2 is a Rhat plot. It shows... This suggests...



\newpage


# References


