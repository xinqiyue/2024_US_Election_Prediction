---
title: "Predicting Electoral Outcomes: Bayesian Modeling of Voter Support Trends for Kamala Harris and Donald Trump in the 2024 Presidential Election"
subtitle: "Predictions shows higher likelyhood for Harris to be the Winner"
author: 
  - Xinqi Yue
  - Yawen Tan
  - Duanyi Su
thanks: "Code and data are available at: [https://github.com/xinqiyue/2024_US_Election_Prediction](https://github.com/xinqiyue/2024_US_Election_Prediction)."
date: today
date-format: long
abstract: "This paper builds a predictive Bayesian model to forecast the 2024 US presidential election using a poll-of-polls approach, analyzing high-quality polls for Kamala Harris and Donald Trump. The model incorporates data on polling methodology, state trends, and candidate support. Our findings indicate that although no candidate is guaranteed to win a total of 270 electoral votes due to lack of polls in certain states, Kamala Harris is more likely to win the election with 222 electoral votes against Donald Trump's 109 electoral votes. This study contributes to an understanding of electoral forecasting, helping us interpret aggregated polling data to anticipate election results."
format: pdf
number-sections: true
table-of-contents: true
toc-depth: 2
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false
library(dplyr)
library(tidyr)
library(knitr)
library(rstanarm)
library(ggplot2)
library(tidyverse)
library(arrow)
library(janitor)
library(lubridate)
library(broom)
library(modelsummary)
library(splines)
library(caret)
```

```{r}
#| include: false
#| warning: false
#| message: false
# load data
president_polls_cleaned_data <- read_parquet('../data/02-analysis_data/president_polls_cleaned_data.parquet')
# transfer date to standard form
president_polls_cleaned_data$end_date <- ymd(president_polls_cleaned_data$end_date)
```

# Introduction
The 2024 U.S. presidential election is generating significant public interest, with recent polling reflecting shifts in candidate support across various demographic and regional groups. Polling data presents challenges due to inherent biases, variability in polling methodology, and regional influences on voter behavior. This study aims to address these challenges using a poll-of-polls approach, aggregating high-quality national and state polls to forecast voter support for Kamala Harris and Donald Trump. By applying Bayesian modeling, this analysis incorporates both the temporal dynamics of candidate support and state-specific trends.

Our model predicts trends in voter support for the 2024 U.S. Presidential Election, focusing on Donald Trump and Kamala Harris. The results, visualized in @fig-modelvisual, indicate stable support for Harris at an estimated 52% nationally, with a confidence interval of approximately 49% to 55%. Trump’s predicted support level centers around 46%, with a range of about 43% to 49%, showing a decreasing trend as the election date nears. State-specific polling results highlight variances, with Harris showing stronger support in traditionally Democratic areas like Maine CD-1, where predicted support reaches around 62%. In contrast, battleground states such as Georgia, Florida, and Pennsylvania exhibit closely contested support levels, reflecting competitive races in these regions. These predictions underscore the variability in voter sentiment across states, illustrating the importance of both national and regional factors shaping the electoral landscape.

In remainder of this paper, we structure our analysis as follows. @sec-data provides a detailed overview of the data used, including the data cleaning process, explanations of the predictor and outcome variables, as well as other variables that contribute to the model. We also present relevant data visualizations to illustrate initial trends and patterns. @sec-model focuses on the model setup and methodology, specifically detailing the Bayesian model used, its underlying assumptions, and software choices. @sec-result presents our main results, including both the model's outputs and the predictions of voter support for the key candidates. In @sec-discussion, we discuss the findings, give broader implications, and highlight the limitations and potential directions for future research. Finally, the appendices provide additional methodological analysis, an idealized survey methodology, and model diagnostics.

## Estimand
Our main goal is to predict who will win the election, Donald trump or Kamala Harris. Specifically, we estimated the voter support rate percentage of Donald Trump and Kamala Harris on election day considering sample size, state and end date, and then calculated the total number of votes obtained by Trump and Harris through the total number of votes in each state, so as to provide a reliable prediction of the election results.


# Data {#sec-data}

## Data Overview {#sec-data-overview}
@sec-data centers on a polling dataset for Donald Trump and Kamala Harris, filtered for quality by including only results from pollsters with a numeric grade above 2.5. Key variables such as state, end date, sample size, candidate name, and support percentage (pct) are identified. The data cleaning process standardizes column names, retains relevant fields, and addresses missing values to ensure high-quality data for analysis. The section includes a table presenting the first six entries of the cleaned analysis data set, alongside multiple graphs: a bar graph comparing candidate support percentages by state, scatter plots illustrating trends in candidate support over time, and visualizations examining the relationship between sample size and support percentages. 

The analysis utilizes FiveThirtyEight's data set of national presidential general election polls [@fivethirtyeight]. Following the approach outlined in [@tellingstories], we aim to predict the election outcome based on this polling data. The analyses were conducted in R [@citeR], utilizing several packages to streamline the process. The tidyverse packages [@citetidyverse] were essential for data simulation and preliminary testing. Initially, the raw data was downloaded using the arrow package [@citearrow], which facilitated efficient handling of large datasets.   

Data cleaning employed dplyr [@citedplyr], tidyr [@citetidyr], and janitor [@citejanitor] to ensure consistent data structure, particularly for renaming columns and removing inconsistencies. Date variables were managed with the lubridate package [@citelubridate], making it easier to handle time-based data accurately. For modeling, rstanarm [@citerstanarm] was used for Bayesian regression modeling, while splines [@citesplines] handled non-linear relationships, and caret [@citecaret] supported model training and validation. The modelsummary [@citemodelsummary] package was used to summarize results, and broom [@citebroom] helped tidy up model outputs. Lastly, ggplot2 [@citeggplot] generated clear visualizations, ensuring effective communication of the findings.

## Data Clean
We clean the raw data to produce the analysis dataset using the tools listed in the @sec-data-overview, providing high-quality data for subsequent election analysis. Firstly, we standardize column names to lowercase and remove special characters. Then, we retain only the fields relevant to the election analysis, such as `state`, `end_date`, `sample_size`, `candidate_name`, and `pct` (percentage support), simplifying the data structure by removing unnecessary columns. Next, we remove rows with missing values and replace empty values in the `state` column with "National," indicating these records pertain to nationwide polls. Additionally, we convert the `end_date` column to date format, ensuring accuracy in date-based filtering. Then, we filter the data to retain only records that meet specific criteria: a `numeric_grade` of 2.5 or higher, a `candidate_name` of either "Kamala Harris" or "Donald Trump" (focusing on these two candidates' support levels), an `end_date` on or after July 21, 2024 (focusing on recent polling when Biden withdrawal from the election), and a non-empty `end_date` (filtering out records with missing dates).

The cleaned data is displayed in @tbl-analysis-data-1, which contains a total of 5 variables:
```{r}
#| label: tbl-analysis-data-1
#| tbl-cap: First 6 entries of Analysis Dataset
#| echo: false
#| warning: false
#| message: false

#Graph
head_analysis_data <- head(president_polls_cleaned_data,6)
# Note there is a type in Description within the original data set itself
knitr::kable(head_analysis_data[, 1:5], format = "simple", col.names = c('State','End date','Sample Size', 'Canadidate Name','PCT'))

```

## Predictors Explanation
- **end date**: The date the poll concluded, marking the end of data collection for that specific poll.In the context of our analysis, we have set a criterion whereby the end dates must be greater than July 21, 2024. This threshold ensures that we are only considering the most recent and relevant polling data as we approach the 2024 election cycle.

- **candidate_name**: The name of the candidate being polled, which in this data set focuses on Donald Trump and Kamala Harris.

- **state**: The U.S. state where the poll was conducted, which allows for state by state analysis and comparison of support levels. @fig-state indicates the distribution of states.The histogram shows the distribution of polling data across different states. States like California and Georgia have high counts, indicating over representation, while states such as Wyoming and South Dakota are underrepresented. 

```{r}
#| label: fig-state
#| fig-cap: Distribution of State
#| echo: false
#| warning: false
#| message: false
#| fig-width: 10
#| fig-height: 6

ggplot(president_polls_cleaned_data, aes(x = state)) +
  geom_bar(fill = "pink") +
  labs(x = "State",
       y = "Count") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Adjust text angle for better readability
```

- **sample size**: The number of respondents in the poll, indicating the scope and potential statistical reliability of the results. @fig-samplesize shows that smaller sample sizes (0 to 500) are significantly more common, indicating a high concentration of data points in this range and these specific sizes are frequently represented in the polling data, while larger sample sizes are relatively scarce.
```{r}
#| label: fig-samplesize
#| fig-cap: Distribution of Sample Size
#| echo: false
#| warning: false
#| message: false
#| fig-width: 6
#| fig-height: 3

# Load necessary libraries
library(ggplot2)
library(dplyr)

# Create a summary of counts for each sample_size
sample_size_summary <- president_polls_cleaned_data %>%
  group_by(sample_size) %>%
  summarise(count = n())

# Create a line plot of sample_size
ggplot(sample_size_summary, aes(x = sample_size, y = count)) +
  geom_line(color = "pink") +
  geom_point(color = "lightblue") +  # Optional: add points to highlight each count
  theme_minimal() +
  labs(#title = "Line Plot of Sample Size Counts",
       x = "Sample Size",
       y = "Count") 
#+ theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Adjust text angle for better readability


```



## Outcome Exaplanation

- **pct**: The support percentage each candidate received in the poll, which serves as the outcome variable for analysis.

pct is the support percentage each candidate received in the poll, which serves as the outcome variable for analysis. This variable is important for understanding the electoral dynamics, as it quantifies the level of public backing for each candidate at a given time and place. By analyzing the pct variable, researchers can assess trends in voter sentiment, compare the effectiveness of campaign strategies, and identify which demographic groups are more inclined to support one candidate over the other. Additionally, fluctuations in the pct can signal shifts in public opinion that may correlate with significant political events, media coverage, or changes in candidates' messaging. This outcome variable allows for a comprehensive analysis of the electoral landscape, providing understandings into how various factors influence voter behavior and preferences throughout the campaign. 

## Explanation of Other Variables Used
- **pollster**: The organization that conducted the poll, providing information on who gathered the data.
  
- **numeric grade**: A quality score assigned to the pollster, with higher values indicating greater reliability. Only pollsters with a score above 2.5 are included to enhance accuracy.

## Measurement
The goal of this measurement is to turn individual voter opinions into a reliable estimate of electoral college outcomes by analyzing polling data. This data, sourced from @fivethirtyeight—a trusted platform known for high standards—includes only polls that meet rigorous quality criteria, ensuring broad representation of likely U.S. voters. Polls provide essential details, such as the pollster’s identity, survey dates, sample size, and methodology, covering data collection mode, demographic weighting, and adjustments to create a representative sample. These quality standards, while robust, are based on historical practices, which may overlook recent methodological shifts or emerging biases.
Polling has inherent limitations. It provides snapshots of voter sentiment at specific times rather than ongoing updates, potentially missing rapid shifts in public opinion, especially near Election Day. Adjustments are made for recenct situations, but participation and response biases—like self-selection and social desirability bias—can still impact accuracy by creating gaps between expressed opinions and actual voting behavior. Additionally, regional polling disparities, with battleground states polled more frequently than "safe" states, can lead to imbalances in representation, highlighting the challenge of achieving uniformly accurate forecasts across the nation.

## Data visualization
### Exploring the Relationship Between State and PCT

```{r}
#| label: fig-pct-state
#| fig-cap: Support for Candidates by State
#| echo: false
#| warning: false
#| message: false
#| fig-width: 14
#| fig-height: 8

ggplot(data = president_polls_cleaned_data, aes(x = state, y = pct, fill = candidate_name)) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_manual(values = c("Donald Trump" = "pink", "Kamala Harris" = "lightblue")) + 
  labs(x = "State",
       y = "Support Percentage (%)") + # Add X-axis and Y-axis
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) 
```
@fig-pct-state compares support percentages for Donald Trump and Kamala Harris across U.S. states, using pink bars for Trump and light blue for Harris. The y-axis shows support percentages up to around 70%, while the x-axis lists states, each with two bars per candidate. @fig-pct-state indicates regional popularity variations. In some states, bars for both candidates are nearly equal in height, indicating competitive support. Other states show one candidate with a clear lead, highlights the varying levels of popularity for each candidate in different regions, which may reflect political, demographic, or regional factors influencing voter preferences. For instance, California leans toward Harris, with a taller blue bar, while Texas favors Trump, with a taller pink bar. These patterns reflect regional political tendencies, suggesting which states might be strongholds or battlegrounds. They highlight potential areas where each candidate could focus efforts to strengthen support or appeal to undecided voters.


### Exploring the Relationship Between End Date and PCT

```{r}
#| label: fig-pct-time
#| fig-cap: Trends in Candidate Support Over Time
#| echo: false
#| warning: false
#| message: false
#| fig-width: 7
#| fig-height: 3

ggplot(data = president_polls_cleaned_data, aes(x = end_date, y = pct, color = candidate_name, group = candidate_name)) +
  #geom_line(size = 1,alpha = 0.5) + 
  geom_point(size = 1) + # Add data point
  geom_smooth(se = FALSE) + 
  scale_color_manual(values = c("Donald Trump" = "pink", "Kamala Harris" = "lightblue")) + 
  labs(x = "End Date",
       y = "Support Percentage (%)",
       color = "Candidate Name") +
  theme_minimal() + 
  #theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(legend.position = "bottom")
```

@fig-pct-time visualizes support percentages for Donald Trump and Kamala Harris over time, with each point representing a poll. The x-axis shows poll end dates, extending beyond July 21st, while the y-axis reflects support percentages. Pink dots represent Trump, and light blue dots represent Harris.nTrend lines for each candidate show Harris consistently above Trump, indicating a slight but steady lead. Harris’s trend remains around 50%, while Trump’s is just below. Both lines are stable, with no major fluctuations in support over time, suggesting limited change in public opinion. The close clustering of points around each trend line indicates steady support levels for both candidates, with Harris maintaining a modest lead throughout the period.



```{r}
#| label: fig-pct-sample-size
#| fig-cap: Support for Candidates by Sample Size
#| echo: false
#| warning: false
#| message: false
#| fig-width: 7
#| fig-height: 3

# Load ggplot2
library(ggplot2)

ggplot(data = president_polls_cleaned_data, aes(x = sample_size, y = pct, color = candidate_name, group = candidate_name)) +
  geom_point(size = 1) + # Add data point
  scale_color_manual(values = c("Donald Trump" = "pink", "Kamala Harris" = "lightblue")) + 
  labs(x = "Sample size",
       y = "Support Percentage (%)",
       color = "Candidate Name") + 
  theme_minimal() + 
  #theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  theme(legend.position = "bottom")
```
@fig-pct-sample-size examines the relationship between poll sample size and support percentage for Donald Trump and Kamala Harris. The x-axis represents poll sample sizes, ranging from a few hundred to over 6,000, while the y-axis shows support percentages. Pink dots indicate Trump’s support, and light blue dots represent Harris. Most polls have sample sizes under 2,000, with support percentages clustering between 40% and 55% for both candidates. As sample sizes increase, support percentages stabilize around the 45%–55% range, though fewer large-sample polls exist. Smaller polls show more variability, with support percentages ranging from 30% to 60%, while larger polls yield more consistent results near 50%.Overall, the plot suggests that larger polls offer more stable estimates of support, while smaller polls tend to show greater fluctuation.



### Exploring the Relationship Between End Date and State and PCT
```{r}
#| label: fig-all-obs
#| fig-cap: Support Rates of Donald Trump and Kamala Harris by State and end date
#| echo: false
#| warning: false
#| message: false
#| fig-width: 8
#| fig-height: 10

state_support_rates <- president_polls_cleaned_data %>%
  group_by(state, candidate_name) %>%
  summarise(avg_pct = mean(pct, na.rm = TRUE)) %>%
  ungroup()

ggplot(president_polls_cleaned_data, aes(x = end_date, y = pct, color = candidate_name)) +
  geom_point(size = 0.7) +
  facet_wrap(~ state, scales = "free_y") +
  labs(title = "Support Rates of Donald Trump and Kamala Harris by State",
       y = "Support Rate (%)",
       x = "Date",
       color = "Candidate Name") +
  theme_minimal() +
  theme(legend.position = "bottom")
```
@fig-all-obs comprises scatter plots illustrating the support rates for Donald Trump and Kamala Harris across various states, with the y-axis representing percentage support and the x-axis indicating the timeline. Red dots represent Trump's support, while blue dots indicate Harris's. The visualization shows fluctuating support levels for both candidates, with Harris generally receiving higher support in states like California and New York, whereas states like Florida and Indiana display a more competitive landscape. The national plot shows trends in support, reflecting periods of gain or loss for both candidates, suggesting that voter sentiment is dynamic and influenced by external factors during the campaign. Overall, the figure highlights the changing electoral support for Trump and Harris across states and time.


# Model {#sec-model}
In this analysis, we use a Bayesian linear regression model to estimate the percentage of support (`pct`) for each candidate in the upcoming US presidential election. The model includes key predictors such as polling end date (`end_date`), candidate (`candidate_name`), sample size (`sample_size`), and state (`state`). Each predictor is selected based on its relevance to the variation in candidate support, as discussed in the data section.

## Model set-up

In this Bayesian framework, support level are modeled as normally distributed and influenced by several predictors: end date, candidate name, sample size, and state. The variable $y_i$ denotes the percentage of votes for a candidate in a specific poll, with $\beta_i$ representing the candidate effect, $\gamma_i$ reflecting the influence of sample size, and $\delta_i$ corresponding to the state effect. The intercept $\alpha$ indicates the baseline poll result, while each $\beta_i$ coefficient quantifies the influence of its associated predictor on the vote percentage. Additionally, the variable $\text{state}_j$ captures the effects attributed to different states, and $\text{end\_date}_{i}$ models temporal trends.

The model can be mathematically expressed as follows:

\begin{align}
y_i | \mu_i, \sigma &\sim \text{Normal}(\mu_i, \sigma) \\ 
\mu_i &= \alpha + \beta_1 \cdot \text{end\_date}_i + \beta_2 \cdot \text{candidate\_name}_i + \beta_3 \cdot \text{sample\_size}_i + \sum_{j=1}^{M} \gamma_j \cdot \text{state}_j \\ 
\alpha &\sim \text{Normal}(50, 10) \\ 
\beta_1, \beta_2, \beta_3 &\sim \text{Normal}(0, 2.5) \\ 
\gamma_j &\sim \text{Normal}(0, 2.5) \\ 
\sigma &\sim \text{Exponential}(1)
\end{align}

Priors are defined as follows. For the intercept, a `Normal(50, 10)` distribution is utilized, reflecting a belief that the baseline support percentage is centered around 50% with moderate variability. This choice indicates a moderately informative prior that captures plausible ranges for the intercept. Each regression coefficient is assigned a `Normal(0, 2.5)` prior, which is weakly informative, allowing flexibility in parameter estimation while minimizing bias. These priors are selected to strike a balance between allowing the data to inform estimates and providing regularization to prevent extreme values and overfitting. The chosen priors are grounded in reasonable expectations regarding support ranges, aiming to enhance the robustness of the model.

Then, the complete model, summarizing the components, can be expressed as:

$$y_i \sim \text{Normal}\left(\alpha + \beta_1 \cdot \text{end\_date}_i + \beta_2 \cdot \text{candidate\_name}_i + \beta_3 \cdot \text{sample\_size}_i + \sum_{j=1}^{M} \gamma_j \cdot \text{state}_j, \sigma^2\right)$$

To further clarify the model:

- **Formula (1)** shows that the response variable $y_i$ is normally distributed, with $\mu_i$ as the expected value and $\sigma$ representing standard deviation.
- **Formula (2)** illustrates that $\mu_i$ is derived from the intercept $\alpha$ and the predictors.
- **Formula (3)** details the basis functions applied to the state variable, allowing for a nuanced relationship between states and vote percentages.
The prior distributions are:
- **Formula (4)** specifies that $\alpha$ has a normal distribution with mean 50 and variance $10^2$, indicating our expectation of average vote percentage.
- **Formula (5)** outlines the priors for $\gamma_k$, which are normal distributions centered at 0 with variance $2.5^2$, reflecting the belief in potentially small effects from state variables.
- **Formula (6)** assigns an exponential distribution to the standard deviation $\sigma$, suggesting that smaller variance is more likely while allowing for broader variations.

## Assumptions of the Bayesian Models

1. **Linearity**: The model assumes a linear relationship between independent variables (predictors) and the dependent variable (outcome, `pct`). The expected outcome is represented as a linear combination of the predictors. Nonlinear effects, if present, may not be fully captured, potentially affecting the model's fit.

2. **Normality of Errors**: It is assumed that the residuals (the differences between observed and predicted values) follow a normal distribution. This assumption is important for making valid inferences; violations can lead to incorrect conclusions and unreliable credible intervals. Diagnostic checks and posterior predictive checks are used to assess model fit and adherence to assumptions.

3. **Homoscedasticity**: The variance of the residuals is expected to be constant across all combinations of the predictors. If residuals display heteroscedasticity (non-constant variance), it can result in inefficient estimates and biased interpretations of the modeled relationships.

4. **Independence of Errors**: The model assumes that errors are independent of one another, meaning the error term for any single observation does not affect the error term for another observation. However, polling data often includes repeated measures from the same pollster, which may introduce dependence among observations.

5. **Additivity**: Predictors are assumed to additively influence `pct`, meaning interactions or non-additive effects are not considered. Future versions of the model might benefit from testing interactions, such as between state and candidate.

6. **Prior Distributions**: Bayesian regression requires the specification of prior distributions for the model parameters (coefficients). The selection of these priors is significant, as they can impact the resulting posterior distributions, particularly when data is limited.

7. **Parameter Estimation**: In Bayesian linear regression, parameters are estimated using a posterior distribution derived from both the likelihood of the observed data and the prior distributions. This framework allows for uncertainty quantification and more flexible inference.

## Software and Validation

The model is implemented using the `rstanarm` package in R, which allows for efficient Bayesian inference with automatic convergence diagnostics. Model fit and convergence were monitored through trace plots and effective sample sizes. To further ensure robustness, we performed posterior predictive checks using `pp_check(model_bayes)` to evaluate model fit and identify any systematic deviations.

Overall, this Bayesian model provides a balanced approach, capturing key effects while maintaining interpretability and flexibility, making it suitable for predicting candidate support percentages in the election context.


### Model justification

In this analysis, we utilize a Bayesian linear regression model to predict the percentage of voter support for Donald Trump and Kamala Harris in the 2024 U.S. Presidential Election. This choice of modeling framework is particularly suitable for our objectives, as it allows for the incorporation of prior knowledge regarding electoral dynamics while updating predictions based on newly observed data. The Bayesian approach provides a robust mechanism for estimating uncertainty in our predictions, which is important in the context of political polling where public sentiment can fluctuate significantly.
The model structure includes key predictors: the polling end date, candidate name, sample size, and state. The use of these predictors is justified by their established relevance in previous electoral analyses, highlighting their roles in shaping voter preferences. The inclusion of `end_date` facilitates the examination of temporal trends in support, reflecting how candidate visibility and public sentiment evolve as the election date approaches.
We model the outcome variable, support percentage (pct), as a normally distributed random variable influenced by these predictors. The mathematical formulation allows for the representation of the intercept, which denotes the baseline support level, alongside coefficients that quantify the influence of each predictor. The priors assigned to the model parameters are carefully chosen to reflect reasonable expectations based on historical voting patterns, thus enhancing the model's interpret ability and effectiveness.
Moreover, the Bayesian framework enables the modeling of potential interactions between state-specific effects and candidate support, allowing us to capture the regional variations that are often observed in electoral outcomes. By incorporating individual pollster effects as fixed coefficients, we can account for the inherent biases associated with different polling organizations, ensuring that our model provides a nuanced view of candidate support.
This model's formulation strikes a balance between complexity and interpret ability, allowing for a comprehensive analysis of the factors influencing voter sentiment while maintaining computational efficiency. The Bayesian approach not only enhances our understanding of electoral dynamics but also provides a statistically sound basis for forecasting potential election outcomes. Overall, the chosen model is well-aligned with the objectives of this study, facilitating a robust analysis of polling data to derive meaningful understandings into the upcoming election.




# Results {#sec-result}

## Model Result

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

model<-
  readRDS(file = here::here("models/election_glm_model.rds"))

```

```{r}
#| echo: false
#| eval: true
#| label: tbl-modelresults
#| tbl-cap: "Model Results of Trump Percentage Vote based on Date and State"
#| warning: false

modelsummary::modelsummary(
  list(
    "Bayesian Model" = model
  ),
  fmt = 2
)
```

@tbl-modelresults provide understandings into the factors influencing voter support for Donald Trump and Kamala Harris, based on a total of 846 observations. The model intercept is estimated at -397.72, serving as a baseline from which other coefficients are interpreted. Notably, the coefficient for the polling end date is 0.02, indicating a positive relationship between the date and support percentage, suggesting that as the election approaches, support for the candidates slightly increases, likely due to heightened visibility and engagement. The coefficient for Kamala Harris is 1.81, reflecting her higher expected support relative to Donald Trump, which indicates her appeal among voters during the polling period.
@tbl-modelresults also includes state-specific coefficients that capture regional variations in support. For instance, states such as Maine CD-1 (4.05), Missouri (1.66), and New Mexico (1.73) show positive coefficients, indicating stronger support for the candidate in these regions. Conversely, negative coefficients for states like Vermont (-2.37), New York (-1.92), and Massachusetts (-1.85) suggest lower support levels, highlighting potential challenges in these areas. 
However, the model's adjusted R² value of -0.056 indicates that the predictors included do not explain a substantial amount of the variability in support percentages, suggesting that other unmeasured factors may influence voter preferences. The log-likelihood value of -2412.946, along with an effective sample size for the expected log pointwise predictive density (ELPD) of -2463.8 and a leave-one-out information criterion (LOOIC) of 4927.6, indicate moderate predictive accuracy. Additionally, the root mean square error (RMSE) of 4.18 suggests that the predicted percentages deviate from actual support levels by approximately 4.18 percentage points on average. Overall, these results underscore the importance of both temporal dynamics and regional differences in predicting voter support, while also indicating a need for further study of additional variables that may more effectively account for observed voter preferences.


```{r}
#| echo: false
#| eval: true
#| label: fig-modelvisual
#| fig-cap: "Predict Posterior Draws and Spline Fit for Vote Percentage"
#| warning: false
#| fig-width: 12
#| fig-height: 8

# Create a new data frame for predictions
new_data <- expand.grid(
  end_date = seq(
    min(president_polls_cleaned_data$end_date),
    max(president_polls_cleaned_data$end_date),
    length.out = 100
  ),
  sample_size = mean(president_polls_cleaned_data$sample_size),
  state = factor(c("National", "Arizona", "California", "Georgia", "North Carolina", "Washington", "Pennsylvania", "New Hampshire", "Texas", "Michigan", "Nevada", "Wisconsin", "Montana", "Florida", "Ohio", "Massachusetts", "Virginia", "South Carolina", "Nebraska CD-2", "Minnesota", "New York", "Nebraska", "Maryland", "New Mexico", "Connecticut", "Rhode Island", "Missouri", "Indiana", "Iowa", "Vermont", "Maine", "Maine CD-1", "Maine CD-2")),
  candidate_name = factor(c("Kamala Harris", "Donald Trump"))  # Only two candidates for simplicity
)

# Generate posterior predictions
posterior_preds <- posterior_predict(model, newdata = new_data)

# Summarize predictions
pred_summary <- new_data %>%
  mutate(
    pred_mean = colMeans(posterior_preds),
    pred_lower = apply(posterior_preds, 2, quantile, probs = 0.025),
    pred_upper = apply(posterior_preds, 2, quantile, probs = 0.975)
  )

# Visualization
ggplot(president_polls_cleaned_data, aes(x = end_date, y = pct, color = candidate_name)) +
  geom_point(aes(shape = state), alpha = 0.5) +  # Use state as shape
  geom_line(
    data = pred_summary,
    aes(x = end_date, y = pred_mean, color = candidate_name),
    size = 1.2,  # Make the line thicker
    inherit.aes = FALSE
  ) +
  geom_ribbon(
    data = pred_summary,
    aes(x = end_date, ymin = pred_lower, ymax = pred_upper),
    alpha = 0.2,
    inherit.aes = FALSE
  ) +
  labs(
    x = "End Date",
    y = "Percentage",
    #title = "Predicted Percentage Over Time",
    color = "Candidate",
    shape = "State"
  ) +
  theme_minimal() +
  theme(
    legend.key.size = unit(1, "cm"),
    legend.text = element_text(size = 8) 
  )



```

@fig-modelvisual produced predicted percentages of voter support for Donald Trump and Kamala Harris over time, as shown in the graph titled "Predicted Percentage Over Time." The y-axis represents the predicted support percentage, while the x-axis indicates polling end dates.
@fig-modelvisual indicates distinct trends in voter support for both candidates. The predictions for Kamala Harris (shown in teal) suggest a mean support level consistently around 52% during this period, with the confidence interval shaded in gray indicating a range from approximately 49% to 55%. This stability suggests that Harris maintains a competitive edge in voter support as the election date approaches.In contrast, the predicted percentages for Donald Trump (shown in red) indicate a mean support level around 46%, with a confidence interval ranging from about 43% to 49%. This pattern highlights a slight downward trend in Trump’s predicted support, suggesting potential challenges in consolidating voter sentiment as the election draws near.
The individual data points on the graph represent specific state polling results, with various shapes indicating different states. For example, Maine CD-1 stands out with a higher predicted support for Harris at approximately 62%, which is significantly above the national average, indicating a strong preference in this district. Conversely, states like Florida and North Carolina exhibit more competitive support levels, with both candidates’ predicted percentages clustering around 47% to 50%.The presence of a broader range of predicted support percentages in battleground states such as Georgia and Pennsylvania reflects the volatility of voter sentiment in these regions, where Trump and Harris show closely contested support. The model indicates that Harris may benefit from higher support levels in traditionally Democratic states, while Trump faces a challenge in securing sufficient backing in key swing states.
Overall, @fig-modelvisual underscore the dynamic nature of voter preferences as the election approaches, with Harris appearing to lead in overall support while Trump must contend with fluctuating voter sentiments in swing states. These predictions provide a view of how various factors, including time and state-specific influences, shape the electoral landscape leading up to the 2024 U.S. Presidential Election.

## Predict Result
```{r}
#| echo: false
#| eval: true
#| label: fig-modelpctsummary
#| fig-cap: "Summary table of average pct for each candidate by state"
#| warning: false


# Create summary table of average pct for each candidate by state
average_pct_summary <- president_polls_cleaned_data %>%
  group_by(state, candidate_name) %>%
  summarise(average_pct = mean(pct, na.rm = TRUE), .groups = 'drop') %>%
  pivot_wider(names_from = candidate_name, values_from = average_pct, 
              names_prefix = "avg_pct_of_")

# Output the table
knitr::kable(average_pct_summary, format = "simple", col.names = c('State','PCT of Trump','PCT of Harris'))

```



```{r}
#| echo: false
#| eval: true
#| label: fig-modelvotenum
#| fig-cap: "Summary total votes for each candidate"
#| warning: false

# Use information from https://state.1keydata.com/state-electoral-votes.php to create dataframe
electoral_votes <- data.frame(
  state = c("Arizona", "California", "Connecticut", "Florida", "Georgia",
            "Indiana", "Iowa", "Maine", "Maine CD-1", "Maine CD-2",
            "Maine CD-3", "Maryland", "Massachusetts", "Michigan", "Minnesota", 
            "Missouri", "Montana", "Nebraska", "Nebraska CD-1",
            "Nebraska CD-2", "Nebraska CD-3", "Nevada", "New Hampshire", 
            "New Mexico", "New York", "North Carolina", "Ohio", 
            "Pennsylvania", "Rhode Island", "South Carolina", 
            "South Dakota", "Texas", "Vermont", "Virginia", 
            "Washington", "Wisconsin"),
  votes = c(11, 55, 7, 29, 16, 11, 6, 4, 1, 1,
            1, 10, 11, 15, 10, 10, 3, 5, 2, 1,
            6, 4, 5, 29, 15, 3, 9, 4, 9, 6, 
            13, 3, 10, 10, 8, 10)
)

# calculate total votes of each candidate
total_votes <- average_pct_summary %>%
  left_join(electoral_votes, by = "state") %>%
  mutate(
    winner = case_when(
      average_pct_summary[2] > average_pct_summary[3] ~ "Trump",
      average_pct_summary[2] < average_pct_summary[3] ~ "Harris",
      TRUE ~ "Tie"  # deal with a tie
    ),
    winning_votes = case_when(
      winner == "Trump" ~ votes,
      winner == "Harris" ~ votes,
      TRUE ~ 0
    )
  ) %>%
  summarise(
    total_trump_votes = sum(winning_votes[winner == "Trump"], na.rm = TRUE),
    total_harris_votes = sum(winning_votes[winner == "Harris"], na.rm = TRUE)
  )

# create table of total votes
total_votes_table <- data.frame(
  Candidate = c("Trump", "Harris"),
  Total_Votes = c(total_votes$total_trump_votes, total_votes$total_harris_votes)
)

knitr::kable(total_votes_table, format = "simple", col.names = c('Candidate', 'Total Votes'))

```

@fig-modelpctsummary produced a summary table of average support percentages for Donald Trump and Kamala Harris across various states, as well as @fig-modelvotenum predicted total vote counts based on these averages. @fig-modelpctsummary highlights significant differences in voter support by state, indicateing regional dynamics as the election approaches.

@fig-modelpctsummary indicates that Kamala Harris tends to have higher support in several key states, such as California, where she leads with an average of 59.98% compared to Donald Trump's 34.29%. Similarly, Maryland shows strong backing for Harris at 62.90%, while Trump receives only 32.39% of the vote. In contrast, Trump demonstrates stronger support in traditionally Republican-leaning states like Indiana, where he averages 57.90%, and Florida, with 51.53% support. The data also highlights a competitive landscape in states like Georgia and Michigan, where the candidates are closely matched; in Georgia, Harris has 47.19% compared to Trump's 48.61%, while in Michigan, Harris garners 47.84% against Trump's 46.92%. 

By combining the average support percentage of each state with the electoral votes in @fig-modelpctsummary, we calculated the predicted total votes of each candidate. Each state supports a large percentage of candidates to get the total number of votes in this state, and the total number of votes refers to @stateElectoralVotes. According to these calculations, @fig-modelvotenum shows that Trump got a total of 109 votes, while Harris got 222 votes. Thus, although both of Donald Trump and Kamala Harris is not guaranteed to win 270 votes due to lack of data in certain states, Harris has obvious advantages in the election, especially with the strong support of several key states, and predicts that she may win this election.


# Discussion {#sec-discussion}

## Overview of the Paper
This study employs a Bayesian modeling approach to forecast the 2024 U.S. presidential election, focusing on candidates Kamala Harris and Donald Trump. By analyzing the dataset of high-quality polls, the research investigates how factors such as polling methodology, sample size, and geographic location influence voter support. The findings indicate that Harris is projected to secure 222 electoral votes, while Trump is expected to receive 109.

These results reflect broader social dynamics that shape electoral behavior. Variations in support across states suggest that regional identities and socio-political contexts significantly influence public opinion. Research indicates that diverse populations often favor candidates advocating for progressive policies, which align with issues such as racial equity, healthcare access, and economic opportunity (@pew2020). Conversely, more conservative regions tend to support traditional Republican platforms, reflecting local values and priorities (@brookings2020). 

## Findings About the World
One finding from this analysis is the importance of temporal dynamics in voter support. The model highlights that the timing of polling can substantially impact the reported support for candidates. This finding suggests that voters’ preferences are not static; rather, they fluctuate based on current events, campaign strategies, and media coverage. This underscore the need for political strategists and candidates to consider timing when conducting polls and planning campaign efforts.

Another finding is the diverse levels of candidate support across states. The analysis shows that voter sentiment differs by region, suggesting that geographic factors shape political preferences. This underscores the value of tailoring campaign efforts to specific areas, as messages that appeal to one state may not be as effective in another. Recognizing these regional differences allows candidates to better engage with voters and adapt their messaging to local priorities

## Limitations of the Study
Despite its contributions, this study has limitations. The reliance on existing polling data introduces potential biases, as varying methodologies among pollsters can lead to discrepancies in reported support levels. Additionally, the model's assumption of a linear relationship between predictors and outcomes may oversimplify the complexities of voter behavior.

Another limitation is the lack of a time series analysis. While the study captures snapshots of voter sentiment at specific moments, it does not account for how trends develop over time. This oversight may obscure patterns of voter behavior that emerge as the election date approaches. Future research should incorporate time series methodologies to better understand how public opinion evolves and to identify trends that could inform campaign strategies.

Moreover, the exclusion of demographic factors such as age, income, and education could further explain variations in voter support. Incorporating these elements into future models may improve the robustness of electoral predictions.

## Future Directions
Future research could investigate the effects of significant events, such as presidential debates or major political announcements, on voter sentiment over time. Incorporating time series analysis would allow for examination of how public opinion shifts in response to these events and help identify patterns that develop as the election date approaches.

Additionally, integrating real-time social media analysis and sentiment tracking could provide a clearer view of how public opinion changes in response to external factors. Expanding the model to include demographic variables, such as age, income, and education, would enhance understanding of voter behavior and the reasons behind electoral choices.

Overall, these approaches would strengthen the analysis and assist political strategists in adapting to changes in voter sentiment more effectively.

\newpage

\appendix

# Appendix {-}

# Methodology Analysis of Texas Politics Project Poll{#sec-Appendix1}

## Introduction
This section provides a examination of the methodology utilized by YouGov for the October 2024 Texas Statewide Survey (@blank2024), stating the reliability of the organization and its methods, along with an analysis of the survey's strengths, weaknesses, and potential improvements.

## Population, Frame, and Sample
- **Population**: The survey aimed to represent Texas registered voters, defined as individuals who meet the eligibility requirements to vote in Texas, including age, residency, and registration status. This demographic is critical given the state’s political landscape and upcoming elections.
  
- **Frame**: The sampling frame is the specific population from which a sample is drawn, constructed from diverse data sources to ensure validity. Key components included:
  - **American Community Survey (ACS)**: This provides demographic information that reflects the socio-economic characteristics of Texas residents, essential for establishing a representative sampling frame.
  - **Public voter registration records**: These ensure that the survey captures a valid sample of registered voters, allowing for accurate political representation.
  - **2020 Current Population Survey (CPS)** and **National Election Pool (NEP) exit polls**: These sources offer understandings into voting behaviors and preferences, enriching the sampling frame with relevant context and historical data.

- **Sample Size**: The initial sample comprised 1,338 respondents, which was refined to 1,200 for the final dataset through a process known as matching. This process enhances the demographic representativeness of the sample across key characteristics such as gender, age, race, and education.

## Sample Recruitment

- **Recruitment Methods**: YouGov employs a proprietary opt-in survey panel that includes approximately 1.5 million U.S. residents. Key recruitment methods include:
  - **Web Advertising Campaigns**: Targeted ads based on keyword searches increase the likelihood of engaging relevant respondents, leveraging digital platforms for broad reach.
  - **Permission-Based Email Campaigns**: This method allows for direct outreach to potential participants who have expressed interest in surveys, ensuring a more willing and engaged respondent pool.
  - **Telephone-to-Web and Mail-to-Web Recruitment**: These methods broaden the outreach, ensuring access to respondents who may not engage online, thus increasing the overall sample diversity.

- **Diversity and Representation**: The multifaceted recruitment strategy is designed to mitigate biases and enhance the demographic diversity of the panel. This is essential for capturing a representative sample in a politically diverse state like Texas.

## Sampling Approach and Trade-offs

- **Two-Stage Sampling Approach**: 
  1. **Target Sample Selection**: A probability sample is drawn from the defined target population, ensuring it accurately reflects the demographic composition of Texas. Probability sampling means that each individual in the population has a known, non-zero chance of being selected.
  2. **Matched Sample Selection**: Each target sample member is matched to one or more respondents from the YouGov panel, utilizing a set of variables available in consumer and voter databases. Matching involves finding respondents in the panel who share key demographic and behavioral traits with the target sample.

- **Strengths**: This methodology allows for the creation of a sample that closely mirrors the target population’s characteristics, theoretically increasing the external validity of the survey results—external validity refers to the extent to which findings can be generalized to a broader context beyond the study sample.

- **Weaknesses**:
  - **Non-Random Selection**: The reliance on an opt-in panel introduces potential biases associated with self-selection. Respondents who choose to participate may differ significantly from those who do not, potentially affecting the survey's internal validity (the degree to which the survey accurately measures what it intends to measure).
  - **Matching Limitations**: While proximity matching aims to find the closest respondents, it may not account for all variables that could influence responses, leading to unobserved biases. Unobserved biases occur when factors influencing survey responses are not measured or controlled for in the analysis.

## Handling Non-Response

- **Weighting Strategy**: To address non-response bias, YouGov implemented a robust weighting methodology:
  - **Propensity Score Adjustment**: This involves estimating the likelihood of response based on demographic characteristics, which are then used to weight the matched cases back to the target population. Propensity score weighting is a statistical technique that adjusts for differences in observed characteristics between respondents and non-respondents.

- **Challenges**: The success of this strategy hinges on accurate assumptions regarding non-response characteristics, which can be difficult to ascertain. If the reasons for non-response are systematically related to the survey topics or demographics, this could undermine the validity of the results, highlighting the importance of addressing potential non-response bias.

## Questionnaire Evaluation

- **Question Design**: The YouGov questionnaire included a series of structured questions aimed at eliciting clear responses regarding voter preferences and opinions on key issues. Structured questions are those that offer fixed response options, facilitating easier analysis.

- **Pros**:
  - **Clarity and Relevance**: Questions were designed to be straightforward, addressing current political concerns likely to engage respondents effectively.
  - **Wide Coverage**: The questionnaire covered a wide array of topics pertinent to the election, providing rich data for analysis and ensuring relevant understandings into voter sentiment.

- **Cons**:
  - **Length and Complexity**: The extensive nature of the questionnaire could lead to respondent fatigue, increasing the likelihood of incomplete or rushed responses, which may affect data quality. Respondent fatigue occurs when participants become tired or disengaged from a survey, leading to lower-quality data.
  - **Framing and Bias**: The manner in which questions are framed can introduce bias. Questions that lack neutral wording may lead to skewed responses based on how they are interpreted by participants, potentially distorting the data collected.

## Recommendations for Improvement

1. **Enhanced Recruitment Strategies**: Consider integrating more diverse recruitment channels, such as partnerships with community organizations, to reach underrepresented groups who may not be captured through standard methods.

2. **Improved Matching Techniques**: Exploring statistical techniques or machine learning approaches for matching respondents could enhance the accuracy of the matched sample.

3. **Shortening the Questionnaire**: Streamlining the questionnaire to focus on the most critical issues could reduce respondent fatigue and improve engagement, ensuring higher quality data collection.

4. **Pilot Testing**: Implementing pilot surveys to test question clarity and structure could help identify potential biases or misunderstandings before full deployment, ensuring that the questions effectively capture the desired information.

5. **Transparency in Weighting Methods**: Clearly communicating the assumptions and methods used in weighting would enhance transparency and allow for a more critical evaluation of the findings, fostering trust in the results.

## Conclusion

In summary, YouGov’s methodology for the October 2024 Texas Statewide Survey demonstrates several strengths, particularly in its diverse recruitment strategies and thorough weighting processes. However, inherent challenges associated with opt-in panels, matching techniques, and questionnaire design warrant careful consideration. By addressing these weaknesses and implementing the suggested improvements, the reliability and validity of future surveys can be enhanced, ultimately providing richer understandings into voter behavior and preferences.

# Idealized Methodology and Survey {#sec-Appendix2}

## Objective and Overview
This survey methodology aims to forecast the U.S. presidential election outcome by gathering representative data from a diverse cross-section of American voters. The target population includes all eligible U.S. voters, spanning a wide array of demographic backgrounds. With a budget of $100,000, this methodology employs probability sampling techniques, effective recruitment, and thorough data validation protocols to ensure data accuracy and minimize bias. By applying probability sampling, each individual has a known chance of selection, allowing the results to be statistically valid and generalizable. This design accounts for demographic, geographic, and political influences, enhancing prediction reliability [@fivethirtyeight; @pewresearch].

### Core Objectives
- **Representative Sampling**: Achieve a sample reflecting U.S. voting demographics, ensuring understandings are applicable to the entire electorate.
- **Data Quality**: Implement validation processes, including cross-verification, to ensure accuracy.
- **Statistical Modeling and Aggregation**: Apply statistical models and aggregate polling data to enhance forecast accuracy, as demonstrated in prior election studies.

## Sampling Strategy
The sampling strategy combines **stratified random sampling** and **quota sampling** for representation across key demographics. Stratified random sampling ensures each subgroup within the population is represented by dividing the population into strata (e.g., age, gender, race) and sampling randomly within each stratum. Quota sampling supplements this by guaranteeing minimum representation across essential demographics.

### Stratification Variables
- **Age Groups**: 18-29, 30-44, 45-64, 65+
  - **Gender**: Male, Female, Non-binary/Other
- **Race/Ethnicity**: White, Black, Hispanic/Latino, Asian, Indigenous, Other
- **Education Level**: No high school, High school graduate, College graduate, Post-graduate
- **Income Bracket**: <$30,000, $30,000-$60,000, $60,000-$100,000, >$100,000
- **Geographic Region**: Northeast, Midwest, South, West

This structure aligns with survey sampling best practices, improving accuracy by ensuring proportional representation [@taherdoost2016sampling; @pewresearch]. However, balancing stratification variables with cost considerations remains a challenge, as over-stratification can be cost-inefficient.

### Sample Size
To achieve high accuracy, we will survey **10,000 respondents**, which provides a ±1% margin of error at a 95% confidence level. This sample size enables detailed subgroup analyses, such as state or demographic-specific trends, increasing the forecast’s reliability.

### Weighting
Post-stratification weighting will adjust for any underrepresented or oversampled demographic groups, ensuring the final sample accurately mirrors the voting population [@kalton2003weighting]. For example, younger voters or minorities will be weighted according to their population proportions.

## Recruitment Strategy
**Multi-channel outreach** (digital ads, email, and civic organization partnerships) will mitigate non-response bias by ensuring diverse respondent participation. This strategy helps correct response imbalances that could distort survey accuracy [@dillman2014internet].

- **Digital Advertisements**: Targeted ads on platforms like Facebook and Instagram to attract diverse demographic groups.
- **Email Outreach**: Invitations to registered voters via available databases.
- **Civic Partnerships**: Collaborations with non-profits to enhance diversity and reduce non-response bias.
- **Incentives**: Participants can enter a lottery for a $100 gift card as motivation.

## Data Validation and Quality Assurance
Ensuring data integrity is essential for an accurate election forecast. Validation protocols will include:
  
  - **Captcha Verification**: To prevent bot entries.
- **Contact Verification**: Confirm email or phone authenticity.
- **Response Time Monitoring**: Flag unusually quick completions for review.
- **Voter Registration Check**: If feasible, confirm registration to verify eligibility.
- **Audits**: Random follow-ups to verify responses.

These measures align with data integrity standards in electoral polling [@pew_survey_methodology].

## Poll Aggregation and Data Analysis
### Poll Aggregation
Using a poll-of-polls approach, this survey’s data will combine with data from reputable polling firms (e.g., YouGov, Ipsos), creating a balanced forecast.

- **Weighting by Methodology and Recency**: Polls are weighted based on methodological rigor and recency, favoring recent data.
- **Bias and Variability Adjustments**: Aggregated data will adjust for any bias among individual polls.

### Modeling Approach
**Bayesian hierarchical models** will address variability across states, demographics, and regions, enabling both popular vote and Electoral College predictions.

## Budget Allocation
- **Recruitment and Outreach**: $70,000
- **Incentives**: $10,000
- **Survey Platform and Administration**: $5,000
- **Validation Tools**: $5,000
- **Analysis Software**: $10,000

## Survey Implementation
The survey will be conducted through **Google Forms**, providing an accessible, cost-effective platform. Access the survey here: [Google Form Survey](https://forms.gle/sAxVuk3n9gV8e2odA).

### Survey Structure

**Title:**
  
  2024 U.S. Presidential Election Forecast Survey

**Introduction:**
  
  We appreciate your participation in this survey, which aims to forecast the outcome of the 2024 U.S. Presidential election. Your responses are essential for our research.

**Please note:**
  
  - Your answers will be treated with complete confidentiality.

- Participation in this survey is voluntary.

- We encourage you to provide honest and thoughtful responses.

- The survey is estimated to take about 5 minutes to complete.

- If you have any questions or concerns, feel free to reach out to our research team at [duanyi.su@mail.utoronto.ca](duanyi.su@mail.utoronto.ca) (Xinqi Yue, Yawen Tan, Duanyi Su).

Thank you for your valuable contribution! As a token of our appreciation, each participant will receive $5 upon completion of the survey.

**Section 1: About Eligibility**
  
  Are you a U.S. citizen?
  
  - Yes

- No (Please end Survey)

Do you meet your state’s residency requirements?
  
  - Yes

- No (Please end Survey)

Will you be 18 years old  or elder by the Election Day?
  
  - Yes

- No (Please end Survey)

Are you registered to vote by the voter registration deadline. (North Dakota does not require voter registration.)

- Yes

- No

- Wish to register later

**Section 2: About Demographics**

The following questions will help us understand the background characteristics of our respondents.

Which age group do you belong to?

- 18-29

- 30-44

- 45-64

- 65 or older

What is your gender?
- Male

- Female

- Prefer not to say

- Other

What is your race or ethnicity? Please select all that apply.
- White

- Black or African American

- Hispanic or Latino

- Asian

- Native American or Alaska Native

- Native Hawaiian or Other Pacific Islander

- Prefer not to say

- Other

Which U.S. state do you currently live in?

[answer box]

What region do you live in within your state?

- Rural

- Suburban

- Urban

- Prefer not to say

What is your political affiliation?

- Democratic

- Republican

- Independent

- Libertarian

- Green Party

- Prefer not to say

- Other

**Section 3: Voting Behavior and Intentions**

These questions focus on voting registration and plans for the upcoming election.

How likely is it that you will vote in the 2024 U.S. Presidential Election?

- Very likely

- Somewhat likely

- Somewhat unlikely

- Very unlikely

If the election were held today, which candidate would you most likely vote for?

- Donald Trump

- Kamala Harris

- Not sure

- Prefer not to say

- Other

How confident are you that your choice would remain the same by Election Day?

- Not at all confident

- Slightly confident

- Moderately confident

- Very confident

- Completely confident

**Section 4: Engagement with the Election**

This section aims to understand how actively our respondents follow and discuss the election.

How closely do you follow news and updates related to the 2024 U.S. Presidential Election?

- Very closely

- Somewhat closely

- Not very closely

- Not at all

How often do you discuss the 2024 U.S. Presidential Election with friends, family, or colleagues?

- Daily

- Weekly

- Occasionally

- Rarely

- Never

**Section 5: Additional understandings**

We appreciate any additional thoughts our respondents may have on the upcoming election.

Do you have any further comments about the factors that might affect the 2024 U.S. Presidential Election? (optional)

[Answer box]

**End Message:**

Thank You for Completing the Survey!

We appreciate your time and thoughtful responses. Your participation is invaluable in helping us gather understandings for our research on the 2024 U.S. Presidential Election forecast. Your answers will contribute to a more comprehensive understanding of voter trends and factors influencing this election.

If you have any further questions or would like to know more about this study, please feel free to reach out to our research team at [anjojoo.xu@mail.utoronto.ca](anjojoo.xu@mail.utoronto.ca).

As a thank you, each participant will receive a $5 reward shortly after survey completion.





---
  
### Design Considerations
- **Question Wording**: Structured to be clear, neutral, and direct.
- **Pilot Testing**: A pre-deployment pilot will refine the question flow, ensuring clarity and ease for respondents.

\newpage
# Model details {#sec-model-details}

## Posterior predictive check

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-ppcheck
#| fig-width: 6
#| fig-height: 4
#| fig-cap: "Posterior Predictive Check of Bayesian Models"

# Load the model using the here function to specify the path
model_bayes <- readRDS("../models/election_glm_model.rds")
# Perform posterior predictive check
pp_check(model_bayes)
```

@fig-ppcheck presents a posterior predictive check (PPC) for Bayesian model, illustrating the relationship between the observed data and the data replicated by the model. On the x-axis, the values of the response variable are depicted, while the y-axis indicates the density or probability of those values. The dark blue curve represents the observed data, denoted as $y$, and is contrasted with multiple light blue curves that signify the model's replicated data, referred to as $y_rep$. 
The close overlap between the dark blue curve and the cluster of light blue curves suggests that the model fits the observed data well, indicating its ability to replicate the distribution of the data accurately. Additionally, the variability among the light blue curves highlights the uncertainty in the model's predictions; if these curves were excessively dispersed or showed minimal overlap with the observed data, it would signal potential issues with the model's fit. 

## Diagnostics
### R-hat Plots

$\hat{R}$ is a diagnostic measure that compares the variance within each chain to the variance between chains. @fig-rhat presents the R-hat values for Bayesian model, which serves as a diagnostic indicator for evaluating the convergence of Markov Chain Monte Carlo (MCMC) chains. The x-axis indicates the R-hat statistic, reflecting the convergence status of each parameter in the model, while the y-axis lacks a specific scale and displays various R-hat values along a vertical line. Each point represents the R-hat value for a different parameter, and their clustering around 1.00 suggests effective convergence.
Additionally, @fig-rhat includes interpretation thresholds for R-hat values: values at or below 1.05 signify satisfactory convergence, while values up to 1.1 may indicate some potential convergence issues but are generally considered acceptable. In contrast, values exceeding 1.1 suggest poor convergence, indicating that further iterations may be necessary to obtain stable estimates. Since most of the R-hat values in @fig-rhat are well below 1.05, we can infer that the Bayesian model that we construnct is likely well-fitted and does not raise significant concerns regarding the convergence of the MCMC process.


```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-rhat
#| fig-cap: "R-hat Plots of Bayesian Model"
#| fig-width: 6
#| fig-height: 4

plot(model_bayes, "rhat")

```

### Trace Plots

Trace plot of  Bayesian model illustrates the sampled values of various parameters across multiple iterations of the Markov Chain Monte Carlo (MCMC) process, and discusses the convergence of the MCMC chains. Organized in a grid format, each row represents a different parameter, while each column corresponds to a specific MCMC chain. The x-axis indicates the iteration number of the MCMC sampling, and the y-axis shows the values of the parameters being sampled, with different colors or line styles potentially representing various MCMC chains. Ideally, the sampled values should fluctuate around a stable mean, indicating effective convergence. Conversely, if any parameter shows a lack of mixing or clear trends, such as drifting over time, it may indicate convergence issues, necessitating additional iterations or adjustments to improve the model. 

@fig-trace presents a trace plot for the Bayesian model which consider different states, variable end date, variable sample size and variable candidate name. We can see that there is no clear separation between the chains and sampled values fluctuate around the stable mean, suggesting the MCMC sampling has successfully converged for most parameters. 


```{r}
#| echo: false
#| eval: true
#| label: fig-trace
#| fig-cap: "Trace Plot of Bayesian Model"
#| warning: false
#| fig-width: 12
#| fig-height: 12

plot(model_bayes, "trace")
```

\newpage


# References


